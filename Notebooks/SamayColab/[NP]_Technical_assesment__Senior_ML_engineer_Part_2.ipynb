{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikorose87/TechChallengeSamay/blob/main/%5BNP%5D_Technical_assesment__Senior_ML_engineer_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22e325b",
      "metadata": {
        "id": "e22e325b"
      },
      "source": [
        "<img src=\"https://uploads-ssl.webflow.com/632f50e291252dcd1cf0c08b/63dc0565438858025d69245a_Samay-logo-gradient.png\" width=\"30%\">\n",
        "\n",
        "# Comprehensive Technical Test:\n",
        "## Lung Sound Analysis for Respiratory Health"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350bff6b",
      "metadata": {
        "id": "350bff6b"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a0cdcd",
      "metadata": {
        "id": "d0a0cdcd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41c24fe",
      "metadata": {
        "id": "d41c24fe"
      },
      "source": [
        "The primary goal of this technical test is to design, develop, and optimize a machine learning solution for detecting and classifying *respiratory diseases*. This will be achieved using a dataset of lung sounds recorded with an electronic stethoscope. The comprehensive IPython Notebook delivered should demonstrate the *candidate's proficiency* in analyzing sensor data for health applications, specifically in the context of pulmonary diseases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf59116",
      "metadata": {
        "id": "fbf59116"
      },
      "source": [
        "## Dataset description\n",
        "\n",
        "The evolution of stethoscope technology has facilitated the high-quality recording of lung sounds from both healthy individuals and those with various pulmonary conditions. This dataset encompasses audio recordings from patients with seven different ailments, including asthma, heart failure, pneumonia, bronchitis, pleural effusion, lung fibrosis, and COPD, alongside normal breathing sounds. Recordings were taken from multiple positions on the chest, as determined by a specialist physician. Each sound was recorded thrice using different frequency filters to highlight specific bodily sounds. This valuable dataset supports the development of automated tools for diagnosing pulmonary diseases through lung sound analysis and can be extended to heart sound studies.\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2352340921001979-gr1.jpg\" width=\"50%\">\n",
        "\n",
        "The dataset comprises audio recordings of lung sounds from 112 subjects, captured using an electronic stethoscope. It includes data from 35 healthy individuals and 77 subjects with various respiratory diseases [1, 2, 3].\n",
        "- **Content:** The audio recordings have been filtered through Bell, Diaphragm, and Extended modes to ensure clarity and precision in sound quality.\n",
        "- **Annotations:** Each audio file is annotated with comprehensive details including the type of lung sound, the disease diagnosis, recording location on the subject's chest, as well as the age and gender of the subjects. This information is crucial for the analysis and classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73be2f62",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-15T16:51:42.357796Z",
          "iopub.status.busy": "2023-12-15T16:51:42.357442Z",
          "iopub.status.idle": "2023-12-15T16:51:42.367552Z",
          "shell.execute_reply": "2023-12-15T16:51:42.366593Z",
          "shell.execute_reply.started": "2023-12-15T16:51:42.357769Z"
        },
        "id": "73be2f62"
      },
      "outputs": [],
      "source": [
        "# Data Manipulation and Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# File System and Path Handling\n",
        "import os\n",
        "import pathlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Signal Processing\n",
        "import scipy\n",
        "import scipy.io\n",
        "import scipy.io.wavfile\n",
        "from scipy import signal\n",
        "from scipy.fft import fftshift\n",
        "from scipy.io import wavfile\n",
        "import scipy.io.wavfile\n",
        "\n",
        "# Image Manipulation\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Miscellaneous\n",
        "import ntpath\n",
        "import random\n",
        "from IPython import display\n",
        "import time\n",
        "\n",
        "# Audio Processing (Librosa)\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "# Importing required libraries for handling HTTP requests and zip files\n",
        "import requests  # Library for making HTTP requests\n",
        "import zipfile   # Library for handling zip files\n",
        "import io        # Library for handling binary data streams"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e4830c",
      "metadata": {
        "id": "a2e4830c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e246fe59",
      "metadata": {
        "id": "e246fe59"
      },
      "source": [
        "# 1. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fcdc64",
      "metadata": {
        "id": "23fcdc64",
        "outputId": "674e08a3-3689-48b3-a1c1-1c88cebe2ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded and extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "# Obtain the current working directory\n",
        "current_path = os.getcwd()\n",
        "\n",
        "# URL of the ZIP file to be downloaded\n",
        "url = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/jwyy9np4gv-3.zip\"\n",
        "\n",
        "# Download the ZIP file from the specified URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the HTTP response status code is 200 (OK)\n",
        "if response.status_code == 200:\n",
        "    # Retrieve the content of the ZIP file\n",
        "    zip_content = response.content\n",
        "\n",
        "    # Extract the content of the ZIP file into a specific folder\n",
        "    with zipfile.ZipFile(io.BytesIO(zip_content), 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"inputdata\")  # Change this to the desired directory path\n",
        "    print(\"File downloaded and extracted successfully.\")\n",
        "else:\n",
        "    print(\"Error downloading the file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b0bc87",
      "metadata": {
        "id": "c7b0bc87"
      },
      "outputs": [],
      "source": [
        "def extract_nested_zip(zip_file_path, extraction_path):\n",
        "    \"\"\"\n",
        "    Extract a zip file, including any nested zip files.\n",
        "    Delete the zip file after extraction.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all the contents into the directory\n",
        "        zip_ref.extractall(extraction_path)\n",
        "\n",
        "        # Iterate through each file in the extracted files\n",
        "        for file in zip_ref.namelist():\n",
        "            # Check if the file is a zip file\n",
        "            if file.endswith('.zip'):\n",
        "                # Construct full path to the nested zip file\n",
        "                nested_zip_path = os.path.join(extraction_path, file)\n",
        "\n",
        "                # Recursively extract the nested zip file\n",
        "                extract_nested_zip(nested_zip_path, extraction_path)\n",
        "\n",
        "                # Optionally, remove the nested zip file after extraction\n",
        "                os.remove(nested_zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec88d35",
      "metadata": {
        "id": "aec88d35"
      },
      "outputs": [],
      "source": [
        "dataset_path = current_path + \"/inputdata/\"  # Change this to the extraction path of the main ZIP file\n",
        "\n",
        "# Look for ZIP files in the extraction directory and extract any nested ZIP files\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith('.zip'):\n",
        "        zip_file_path = os.path.join(dataset_path, file)\n",
        "        extract_nested_zip(zip_file_path, dataset_path)\n",
        "\n",
        "# Define the path to the dataset directory\n",
        "data_dir = pathlib.Path(dataset_path)\n",
        "\n",
        "# List the files in the directory\n",
        "commands = np.array(os.listdir(data_dir))\n",
        "\n",
        "# Filter and remove 'README.md' from the list of files\n",
        "commands = commands[commands != 'README.md']\n",
        "\n",
        "# Split each element in the list by commas, and then by underscores\n",
        "a = [line.split(',') for line in commands]\n",
        "b = [x[0].split('_') for x in a]\n",
        "\n",
        "# Extract the label only if the element has at least two parts\n",
        "label = [c[1] for c in b if len(c) > 1]\n",
        "\n",
        "# Convert labels to lowercase\n",
        "label = [x.lower() for x in label]\n",
        "\n",
        "# Iterate through the labels and perform label consolidation\n",
        "for i in range(336):\n",
        "    if label[i] == 'asthma and lung fibrosis':\n",
        "        label[i] = 'asthma'\n",
        "    elif label[i] == 'heart failure + copd' or label[i] == 'heart failure + lung fibrosis ':\n",
        "        label[i] = 'heart failure'\n",
        "    else:\n",
        "        label[i] = label[i]\n",
        "\n",
        "def return_unique_labels(labels):\n",
        "    # Removing duplicates from the list while maintaining the order\n",
        "    unique_labels = []\n",
        "    for label in labels:\n",
        "        if label not in unique_labels:\n",
        "            unique_labels.append(label)\n",
        "    return unique_labels\n",
        "\n",
        "labels = return_unique_labels(label)\n",
        "\n",
        "# Initialize an empty array to store the full paths of WAV files\n",
        "wav_files = []\n",
        "\n",
        "# Iterate through the files in the directory\n",
        "for file in os.listdir(dataset_path):\n",
        "    # Check if the file is a WAV file\n",
        "    if file.endswith(\".wav\"):\n",
        "        # Add the full path of the file to the array\n",
        "        wav_files.append(os.path.join(dataset_path, file))\n",
        "\n",
        "# Initialize an array to store the data of each WAV file\n",
        "wav_data = []\n",
        "\n",
        "# Iterate through the WAV file paths in the wav_files array\n",
        "for filepath in wav_files:\n",
        "    # Read the WAV file using scipy.io.wavfile\n",
        "    sample_rate, data = scipy.io.wavfile.read(filepath)\n",
        "\n",
        "    # Add the data, sample rate, file path, and data type to the wav_data array\n",
        "    wav_data.append({\n",
        "        \"file_path\": filepath,\n",
        "        \"sample_rate\": sample_rate,\n",
        "        \"data\": data,\n",
        "        \"data_type\": data.dtype\n",
        "    })\n",
        "\n",
        "\n",
        "# Ensure the number of labels matches the number of WAV files\n",
        "assert len(label) == len(wav_data)\n",
        "\n",
        "# Extracting only the 'data' from each WAV file\n",
        "data_values = [item['data'] for item in wav_data]\n",
        "\n",
        "# Creating a DataFrame with 'data' and 'label'\n",
        "sound_df = pd.DataFrame({\n",
        "    'data': data_values,  # Column 'data' containing waveform data arrays\n",
        "    'label': label        # Column 'label' containing labels\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a723c4",
      "metadata": {
        "id": "73a723c4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f2a2823",
      "metadata": {
        "id": "1f2a2823"
      },
      "source": [
        "# Machine Learning Algorithm Design and Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95067d0e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-15T16:52:11.247315Z",
          "iopub.status.busy": "2023-12-15T16:52:11.247024Z",
          "iopub.status.idle": "2023-12-15T16:52:11.345973Z",
          "shell.execute_reply": "2023-12-15T16:52:11.345112Z",
          "shell.execute_reply.started": "2023-12-15T16:52:11.247291Z"
        },
        "id": "95067d0e"
      },
      "outputs": [],
      "source": [
        "# Determine the maximum length of audio data in the dataset\n",
        "max_length =\n",
        "\n",
        "# Pad the audio data\n",
        "padded_data ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ce3950",
      "metadata": {
        "id": "f5ce3950",
        "outputId": "06002212-9b0f-4c85-b383-79b7374ff702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(336, 120000)\n"
          ]
        }
      ],
      "source": [
        "print(padded_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aa7c13e",
      "metadata": {
        "id": "3aa7c13e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41797b67",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-15T16:52:38.269973Z",
          "iopub.status.busy": "2023-12-15T16:52:38.269564Z",
          "iopub.status.idle": "2023-12-15T16:52:38.275879Z",
          "shell.execute_reply": "2023-12-15T16:52:38.274907Z",
          "shell.execute_reply.started": "2023-12-15T16:52:38.269939Z"
        },
        "id": "41797b67"
      },
      "source": [
        "- Add your code here"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30627,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}